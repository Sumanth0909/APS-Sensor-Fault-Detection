{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "we will use this file to do the validation\n",
    "\n",
    "using the \"aps_failure_training_set1.csv\" file we will validate both \"test.csv\" file and \"train.csv\" file\n",
    "\n",
    "to do the validation, we will fetch the number of columns/features, the names of columns/features \n",
    "and their distribution from the \"aps_failure_training_set1.csv\" file and \"test.csv\" , \"train.csv\"\n",
    "\"test.csv\" , \"train.csv\" -- both are inside \"dataset\" folder\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "to validate, check whether \n",
    "\n",
    "1) the number of columns/features are same in \"aps_failure_training_set1.csv\" file and \"test.csv\" , \"train.csv\"\n",
    "2) the names of columns/features are same in \"aps_failure_training_set1.csv\" file and \"test.csv\" , \"train.csv\"\n",
    "3) the distribution of each of the columns/features are same in \"aps_failure_training_set1.csv\" file and \n",
    "\"test.csv\" , \"train.csv\" \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "google search \"scipy stats ks_2samp\" -- go to the official documentation\n",
    "use this\n",
    "\n",
    "null hypothesis -- both have same distribution\n",
    "alternate hypothesis -- both have different distribution\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "sample1 = stats.uniform.rvs(size=100, random_state=rng)\n",
    "sample2 = stats.norm.rvs(size=110, random_state=rng)\n",
    "response = stats.ks_2samp(sample1, sample2)\n",
    "\n",
    "# we reject null hypothesis -- if \"p-value\" < 0.05   (ie we accept the alternate hypothesis)\n",
    "# ie if \"p-value\" <= 0.05   => we have to RE-TRAIN our model\n",
    "\n",
    "# ie if \"p-value\" > 0.05  =>  both have same distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                        # Anomaly detection \n",
    "''' \n",
    "anomaly detection is a statistical technique that identifies data points, events, or observations \n",
    "that are different from what's normal or expected. It's also known as outlier detection\n",
    "\n",
    "\n",
    "these are the anomalies that we can have in our dataset -\n",
    "\n",
    "1) outliers\n",
    "2) high null values\n",
    "3) missing columns\n",
    "4) for categorical columns, we dont have expected values (ex - 'gender', expected values are 'male' and 'female' \n",
    "now if we get a new value called as 'third gender' , then what to do?)\n",
    "5) for target column (for classification problem), expected values anomaly\n",
    "(ex - in our case, we have only two classes in the end - ie 'pos' and 'neg' -- now what if we have some\n",
    "datapoints in the new data, which better belong to a new class itself called as 'maybe')\n",
    "\n",
    "'''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first drop those columns which have null values > 30% of the total number of values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"E:\\E\\DATA SCIENCE INEURON\\Machine Learning Projects (Industry Grade Projects)\\1) Sensor Fault Detection\\aps_failure_training_set1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()  # gives how many null values are there\n",
    "\n",
    "(df.isnull().sum()/df.shape[0])*100   # gives how many null values are there -- as a % of toal number of values in each column\n",
    "\n",
    "(df.isnull().sum()/df.shape[0]).values # gives values\n",
    "\n",
    "(df.isnull().sum()/df.shape[0]).index # gives column names\n",
    "\n",
    "\n",
    "# let us zip these 2 together and use a for loop \n",
    "for column_name, missing_percentage in zip((df.isnull().sum()/df.shape[0]).index,(df.isnull().sum()/df.shape[0]).values):\n",
    "    print(column_name, missing_percentage * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column_names = []    # a list which contains the names of columns which we will drop\n",
    "                          # ie those columns whose null values are > 70% of total number of values in that column\n",
    "\n",
    "for column_name, missing_percentage in zip((df.isnull().sum()/df.shape[0]).index,(df.isnull().sum()/df.shape[0]).values):\n",
    "    print(column_name, missing_percentage * 100)\n",
    "    if missing_percentage > 0.7:\n",
    "        drop_column_names.append(column_name)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aps_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
